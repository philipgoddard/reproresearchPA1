---
title: "Reproducible Research: Peer Assessment 1"
output: 
  html_document:
    keep_md: true
---

## Loading and preprocessing the data

First lets load up my favorite libraries for this job, and read the data. Im going to convert the date immediately from a character string to date. Its good practice to do investigate some summaries of the data to avoid suprises, so lets do that too.

```{r loadup, message = FALSE, warning = FALSE}
library("dplyr"); library("ggplot2"); library("lattice"); library("gridExtra")

dataset <- read.csv(file = 'activity.csv',
                 header = TRUE,
                 stringsAsFactors = FALSE)

dataset$date <- as.Date(dataset$date)

# quick peek at dataset
head(dataset)
summary(dataset)
```

## What is mean total number of steps taken per day?

This is fairly straightforward. Lets use dplyr, as it is the best tool for the job. Firstly a histogram for the total steps per day:

```{r totalsteps, fig.width = 10}
# first get total steps by grouping by day, and taking care when
# summarising to remove NA's
total_steps <- dataset %>%
  group_by(date) %>%
  summarise(total = sum(steps, na.rm = T))

plot1 <- ggplot(total_steps, aes(total, na.rm = T)) +
  geom_histogram(color = 'blue', fill = 'blue', alpha = 0.5, binwidth = 1000) +
  xlim(c(0,25000)) +
  xlab('total daily steps') +
  ylab('frequency') +
  ggtitle('daily totals histogram') +
  scale_y_continuous(breaks=c(0, 2, 4, 6, 8, 10)) +
  theme_bw()

plot1
```

Im also going to create a little function to calculate the mean and median total number of steps taken per day. This will hopefully come in handy later as well!

```{r}
# make a summary function for mean and median.
# I am careful to ensure that na.rm is true!
MeanMedian <- function(x){
  funs <- c(mean, median)
  vapply(funs, function(f) f(x, na.rm = T), numeric(1))
}

# we see below the mean and median number of steps taken per day
MeanMedian(total_steps$total)
```

As a comment, it seems odd that 10 days have approx 0 - 500 steps. Perhaps the device was not being worn? Further investigation would be required here if this was a 'real' study.

## What is the average daily activity pattern?

Once again, I will use dplyr as it is well suited for this job.
```{r dailyactivity}
# group by interval this time
daily_activity <- dataset %>%
  group_by(interval) %>%
  summarise(average = mean(steps, na.rm = T))

# quick peek at data
daily_activity
```

The lattice xyplot() can be used to knock up a quick time series plot. We can also subset to find the max average daily activity. summary() could have been alternativly.

```{r, fig.width = 10}
xyplot(average ~ interval,
       data = daily_activity,
       type = c("l"),
       ylab = "mean steps")

# subset to find the max average daily activity
daily_activity[daily_activity$average == max(daily_activity$average), ]
```

## Imputing missing values

Time for a bit of fun...

```{r impute}
# firstly determine number of missing values.
# note from summary taken initially we know they are all in 
# steps column
sum(is.na(dataset))

# to impute, find mean and sd for each interval
# then draw from a (absolute, as negative steps doesnt make sense)
# random normal distribution for missing samples

# first group by interval, and determine the mean and sd for each interval
intervalMeanSd <- dataset %>%
  group_by(interval) %>%
  summarise(intMean = mean(steps, na.rm = T),
            intSd = sd(steps, na.rm = T))

# merge with the origional dataset so have the mean and sd columns
intervalMeanSd <- merge(dataset, intervalMeanSd, by = 'interval', all = F)

# determine the row numbers of missing values
naIndex <- which(is.na(intervalMeanSd$steps))

# set seed for reproduceability, and impute
set.seed(100)
intervalMeanSd[naIndex, ] <- intervalMeanSd[naIndex, ] %>%
  mutate(steps = abs(rnorm(n(), mean = intMean, sd = intSd )))

# finally, select only columns of interest, and
# confirm no missing values
imputeData <- select(intervalMeanSd, steps, date, interval)
sum(is.na(imputeData))
```

Now we can repeat the steps above with our newly imputed version of the data. It would be nice to compare the two sets as well (one with NA's removed, one with imputation)

```{r totalimpute, fig.width = 10}
total_steps2 <- imputeData %>%
  group_by(date) %>%
  summarise(total = sum(steps))

plot2 <- ggplot(total_steps2, aes(total, na.rm = T)) +
  geom_histogram(color = 'red', fill = 'red', alpha = 0.5, binwidth = 1000) +
  xlim(c(0,25000)) +
  xlab('total daily steps') +
  ylab('frequency') +
  ggtitle('daily totals histogram, NAs imputed') +
  scale_y_continuous(breaks=c(0, 2, 4, 6, 8, 10)) +
  theme_bw()

grid.arrange(plot1, plot2, ncol = 2)

# lets have a look at the mean and median, and also compare
# to the origional data
rbind(MeanMedian(total_steps2$total), MeanMedian(total_steps$total))
```

We see there are far less days with 0-1000 steps, and that the mean and median have both increased.

## Are there differences in activity patterns between weekdays and weekends?

For this, weekdays() and a dplyr chain with a bit of mutating does the trick. A lattice xyplot() seems suitable for making a quick, neat plot.

```{r weekends, fig.width = 10}
dayData <- imputeData %>%
  mutate(weekday = weekdays(date)) %>%
  mutate(isWeekend = factor(weekday == 'Saturday' | weekday == 'Sunday',
                            labels = c('Weekday','Weekend'))) %>%
  group_by(isWeekend, interval) %>%
  summarise(mean = mean(steps))

xyplot( mean ~ interval | isWeekend,
       data = dayData,
       type = c("l"),
       layout = c(1, 2),
       ylab = "mean steps")

```

We can see there is indeed a difference in activity between weekends and weekedays. Both peak around interval 800, however the level of activity is in general higher on weekends.